{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import praw\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../.secret/reddit/ZSDSFI_client_id.txt') as f:\n",
    "    client_id = f.read()\n",
    "\n",
    "with open('../../../.secret/reddit/ZSDSFI_client_secret.txt') as f:\n",
    "    client_secret = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=\"ZS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit_posts(\n",
    "    reddit_praw: praw.reddit.Reddit,\n",
    "    sub_name: str,\n",
    "    sort_by: str,\n",
    "    time_filter: str = None,\n",
    "    limit: int = 1000,\n",
    "    return_time = True\n",
    "    ):\n",
    "    \"\"\"Returns a DataFrame consisting of PRAW submission objects. \n",
    "    These objects contain data about body, comments, and other aspects of a Reddit post.\n",
    "    The function needs to take in a PRAW Reddit object and a subreddit name, and a \n",
    "    sorting option (new, hot, or top).\n",
    "\n",
    "    Optionally takes in a time filter if sorting by top.\n",
    "    This  determines which time period of top posts to retrieve (hour, day, week, month, year, all).\n",
    "\n",
    "    By defualt, returns a tuple of the DataFrame and the time the function was run. \n",
    "    This may be updated, but it's important to not when a set of submissions was retrieved,\n",
    "    since subreddits are getting new submissions constantly and Reddit only keeps 1000 of them\n",
    "    on the website at any given time. \n",
    "    The return_time parameter can be set to False. \n",
    "    \"\"\"\n",
    "    time_run = dt.datetime.now()\n",
    "\n",
    "    posts = []\n",
    "\n",
    "    subreddit = reddit_praw.subreddit(sub_name)\n",
    "\n",
    "    if sort_by == 'new':\n",
    "        submissions = subreddit.new(limit=limit)\n",
    "    elif sort_by == 'hot':\n",
    "        submissions = subreddit.hot(limit=limit)\n",
    "    elif sort_by == 'top':\n",
    "        submissions = subreddit.top(limit=limit, time_filter=time_filter)\n",
    "    else:\n",
    "        print(f'Function currently does not support sorting by {sort_by}.')\n",
    "        return\n",
    "    \n",
    "    for submission in submissions:\n",
    "        posts.append([submission])\n",
    "    \n",
    "    df = pd.DataFrame(posts)\n",
    "    df.columns = ['submission']\n",
    "\n",
    "    if time_filter:\n",
    "        if time_filter == 'all':\n",
    "            tf_str = ' (from all time) '\n",
    "        else:\n",
    "            tf_str = f' (in the past {time_filter}) '\n",
    "    else:\n",
    "        tf_str = ' '\n",
    "\n",
    "    print(f'Collected {len(posts)} {sort_by.upper()} submissions{tf_str}from r/{sub_name} as of {time_run.strftime(\"%m/%d/%Y at %H:%M\")}.')\n",
    "\n",
    "    if return_time:\n",
    "        return (df, time_run)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_data(\n",
    "        submission_df, \n",
    "        time_run: dt.datetime = None, \n",
    "        drop_24 = False\n",
    "        ):\n",
    "    \"\"\"Returns a DataFrame displaying information about a set of submissions.\n",
    "    Takes in a DataFrame output by get_reddit_posts() containing a 'submission',\n",
    "    which should consist of PRAW submission objects.\n",
    "\n",
    "    If drop_24 is True, drops any submissions less than 24 hours old, which may\n",
    "    not have a sufficient number of comments/votes for analysis.\n",
    "    \"\"\"\n",
    "    df = submission_df.copy()\n",
    "    df['title'] = df['submission'].apply(lambda x: x.title)\n",
    "    df['created_utc'] = df['submission'].apply(lambda x: x.created_utc)\n",
    "    df['datetime'] = df['created_utc'].apply(lambda x: dt.datetime.fromtimestamp(x))\n",
    "    df['id'] = df['submission'].apply(lambda x: x.id)\n",
    "    df['url'] = df['submission'].apply(lambda x: x.url)\n",
    "    df['selftext'] = df['submission'].apply(lambda x: x.selftext)\n",
    "    df['post_hint'] = df['submission'].apply(lambda x: x.post_hint if 'post_hint' in vars(x) else None)\n",
    "    df['score'] = df['submission'].apply(lambda x: x.score)\n",
    "    df['upvote_ratio'] = df['submission'].apply(lambda x: x.upvote_ratio)\n",
    "    df['num_comments'] = df['submission'].apply(lambda x: x.num_comments)\n",
    "\n",
    "    # There is occasionally an HTTP 429 error with the next line, but simply running it again usually works.\n",
    "    \n",
    "    try:\n",
    "        df['comments'] = df['submission'].apply(lambda x: x.comments)\n",
    "    except:\n",
    "        df['comments'] = df['submission'].apply(lambda x: x.comments)\n",
    "\n",
    "    if drop_24:\n",
    "        df = df[df['datetime'] < time_run - dt.timedelta(days=1)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new, time_run_new = get_reddit_posts(reddit, sub_name='askreddit', sort_by='new', limit=1000)\n",
    "print(time_run_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell may have to run twice if HTTP 429 response\n",
    "\n",
    "df_new = get_posts_data(df_new, time_run=None, drop_24=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['datetime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keeping only posts that are at least 24 hours old\n",
    "\n",
    "# df_new_all = df_new.copy()\n",
    "\n",
    "# df_new = df_new[df_new['datetime'] < time_run_new - dt.timedelta(days=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_pickle(\n",
    "    f'./data/askreddit_new_reddit_data_{time_run_new.strftime(\"%m_%d_%Y\")}.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace string below with appropriate file name\n",
    "\n",
    "# reddit_data_file = './data/askreddit_new_reddit_data_09_15_2023.pkl'\n",
    "\n",
    "# df_new = pd.read_pickle(reddit_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Top (year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_year, time_run_top_year = get_reddit_posts(reddit, sub_name='askreddit', sort_by='top', time_filter='year', limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell may have to run twice if HTTP 429 response\n",
    "\n",
    "df_top_year = get_posts_data(df_top_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_year.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_year['datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_year['datetime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_year.to_pickle(\n",
    "    f'./data/askreddit_top_year_reddit_data_{time_run_top_year.strftime(\"%m_%d_%Y\")}.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace string below with appropriate file name\n",
    "\n",
    "# reddit_data_file = './data/askreddit_top_year_reddit_data_09_15_2023.pkl'\n",
    "\n",
    "# df_top_year = pd.read_pickle(reddit_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_top_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Top (month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_month, time_run_top_month = get_reddit_posts(reddit, sub_name='askreddit', sort_by='top', time_filter='month', limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell may have to run twice if HTTP 429 response\n",
    "\n",
    "df_top_month = get_posts_data(df_top_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_month.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_month['datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_month['datetime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_month.to_pickle(\n",
    "    f'./data/askreddit_top_month_reddit_data_{time_run_top_month.strftime(\"%m_%d_%Y\")}.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace string below with appropriate file name\n",
    "\n",
    "# reddit_data_file = './data/askreddit_top_all_reddit_data_09_15_2023.pkl'\n",
    "\n",
    "# df_top_all = pd.read_pickle(reddit_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_top_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Top (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_all, time_run_top_all = get_reddit_posts(reddit, sub_name='askreddit', sort_by='top', time_filter='all', limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell may have to run twice if HTTP 429 response\n",
    "\n",
    "df_top_all = get_posts_data(df_top_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_all['datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_all['datetime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_all.to_pickle(\n",
    "    f'./data/askreddit_top_all_reddit_data_{time_run_top_all.strftime(\"%m_%d_%Y\")}.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace string below with appropriate file name\n",
    "\n",
    "# reddit_data_file = './data/askreddit_top_all_reddit_data_09_15_2023.pkl'\n",
    "\n",
    "# df_top_all = pd.read_pickle(reddit_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_top_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot, time_run_hot = get_reddit_posts(reddit, sub_name='askreddit', sort_by='hot', limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell may have to run twice if HTTP 429 response\n",
    "\n",
    "df_hot = get_posts_data(df_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot['datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot['datetime'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot.to_pickle(\n",
    "    f'./data/askreddit_hot_reddit_data_{time_run_hot.strftime(\"%m_%d_%Y\")}.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace string below with appropriate file name\n",
    "\n",
    "# reddit_data_file = './data/askreddit_hot_reddit_data_09_15_2023.pkl'\n",
    "\n",
    "# df_hot = pd.read_pickle(reddit_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hot.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
